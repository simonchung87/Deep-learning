{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017362,
     "end_time": "2021-01-02T02:41:49.813495",
     "exception": false,
     "start_time": "2021-01-02T02:41:49.796133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T02:41:49.865756Z",
     "iopub.status.busy": "2021-01-02T02:41:49.864925Z",
     "iopub.status.idle": "2021-01-02T02:41:54.632531Z",
     "shell.execute_reply": "2021-01-02T02:41:54.631295Z"
    },
    "papermill": {
     "duration": 4.802447,
     "end_time": "2021-01-02T02:41:54.632665",
     "exception": false,
     "start_time": "2021-01-02T02:41:49.830218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import matplotlib.image as img\n",
    "# import warnings\n",
    "import warnings\n",
    "# filter warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.models as models\n",
    "import time\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015778,
     "end_time": "2021-01-02T02:41:54.664637",
     "exception": false,
     "start_time": "2021-01-02T02:41:54.648859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T02:41:54.711313Z",
     "iopub.status.busy": "2021-01-02T02:41:54.709094Z",
     "iopub.status.idle": "2021-01-02T02:41:54.712144Z",
     "shell.execute_reply": "2021-01-02T02:41:54.712741Z"
    },
    "papermill": {
     "duration": 0.032347,
     "end_time": "2021-01-02T02:41:54.712893",
     "exception": false,
     "start_time": "2021-01-02T02:41:54.680546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Musicdata(torch.utils.data.Dataset):\n",
    "    def __init__(self, npz, mode='train'):\n",
    "        npzfile = np.load(npz)\n",
    "        self.mode = mode   \n",
    "        self.x = npzfile['arr_0']\n",
    "        self.x = [one.reshape(1,640,128) for one in self.x]\n",
    "        self.y = npzfile['arr_1']\n",
    "\n",
    "        \n",
    "                    \n",
    "    def __getitem__(self, index):\n",
    "        data = torch.tensor(self.x[index], dtype = torch.float32)\n",
    "        #data = transforms(data)\n",
    "        if self.mode == 'test': \n",
    "            return data\n",
    "        genre = [np.where(one == 1)[0][0] for one in self.y]\n",
    "        genre = torch.tensor(int(genre[index]))\n",
    "        return data, genre\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T02:41:54.752744Z",
     "iopub.status.busy": "2021-01-02T02:41:54.751854Z",
     "iopub.status.idle": "2021-01-02T02:42:49.698866Z",
     "shell.execute_reply": "2021-01-02T02:42:49.697543Z"
    },
    "papermill": {
     "duration": 54.969999,
     "end_time": "2021-01-02T02:42:49.699021",
     "exception": false,
     "start_time": "2021-01-02T02:41:54.729022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train = Musicdata('../input/fma-small-npz/shuffled_train.npz', mode='train')\n",
    "dataset_val = Musicdata('../input/fma-small-npz/shuffled_valid.npz', mode='val')\n",
    "dataset_test = Musicdata('../input/fma-small-npz/test_arr.npz', mode='test')\n",
    "train_loader = DataLoader(dataset_train, batch_size = 64, shuffle=False)\n",
    "val_loader = DataLoader(dataset_val, batch_size = 64, shuffle=False)\n",
    "test_loader = DataLoader(dataset_test, batch_size = 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015907,
     "end_time": "2021-01-02T02:42:49.732432",
     "exception": false,
     "start_time": "2021-01-02T02:42:49.716525",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Building Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T02:42:49.770081Z",
     "iopub.status.busy": "2021-01-02T02:42:49.769173Z",
     "iopub.status.idle": "2021-01-02T02:42:49.773689Z",
     "shell.execute_reply": "2021-01-02T02:42:49.773076Z"
    },
    "papermill": {
     "duration": 0.025308,
     "end_time": "2021-01-02T02:42:49.773816",
     "exception": false,
     "start_time": "2021-01-02T02:42:49.748508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def configuration(number_of_block):\n",
    "#   cfg_list = []\n",
    "#   forward_block = number_of_block\n",
    "#   if number_of_block > 5:\n",
    "#     forward_block = number_of_block - number_of_block//2\n",
    "#   for i in range(number_of_block):\n",
    "#     if i <= forward_block:\n",
    "#       c_out = 2**(4+i)\n",
    "#       cfg_list += [c_out, c_out, \"M\"]\n",
    "#     if i > forward_block:\n",
    "#       c_out = c_out/2\n",
    "#       cfg_list += [c_out, c_out, \"M\"]\n",
    "\n",
    "#   return cfg_list\n",
    "\n",
    "# for i in range(8):\n",
    "#   print(\"number_of_block =\", i)\n",
    "#   print(configuration(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T02:42:49.825330Z",
     "iopub.status.busy": "2021-01-02T02:42:49.823183Z",
     "iopub.status.idle": "2021-01-02T02:42:49.826154Z",
     "shell.execute_reply": "2021-01-02T02:42:49.826730Z"
    },
    "papermill": {
     "duration": 0.037087,
     "end_time": "2021-01-02T02:42:49.826888",
     "exception": false,
     "start_time": "2021-01-02T02:42:49.789801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def configuration(number_of_block, initial_size=1, th_1=3, th_2=5):\n",
    "    cfg_list = []\n",
    "    c_out = initial_size\n",
    "    for i in range(number_of_block):\n",
    "        if i < th_1: # i=0,1,2,...,th_1 只有一層捲積\n",
    "            c_out = initial_size * 2**i\n",
    "            cfg_list += [int(c_out), \"M\"]\n",
    "        if i >= th_1 and i < th_2: # \n",
    "            c_out *= 2\n",
    "            cfg_list += [int(c_out), int(c_out), \"M\"]\n",
    "        if i >= th_2: # i=th_2,...,number_of_block 只有一層捲積，開始變小\n",
    "            c_out /= 2\n",
    "            cfg_list += [int(c_out), \"M\"]\n",
    "    return cfg_list, int(c_out)\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 1\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T02:42:49.876566Z",
     "iopub.status.busy": "2021-01-02T02:42:49.874447Z",
     "iopub.status.idle": "2021-01-02T02:42:49.877354Z",
     "shell.execute_reply": "2021-01-02T02:42:49.877931Z"
    },
    "papermill": {
     "duration": 0.035153,
     "end_time": "2021-01-02T02:42:49.878077",
     "exception": false,
     "start_time": "2021-01-02T02:42:49.842924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, number_of_block, c_out):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.c_out = c_out\n",
    "        self.number_of_block = number_of_block\n",
    "#         self.LSTM = nn.LSTM(c_out, hidden_size, num_layers, batch_first = True)\n",
    "        self.classifier = nn.Sequential(\n",
    "                nn.Dropout(),\n",
    "                nn.Linear(int(c_out*640*128/4**number_of_block), 512),\n",
    "                nn.ReLU(True),\n",
    "                nn.Dropout(),\n",
    "                nn.Linear(512, 512),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(512, 8),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        #print(x.shape) # batch_size, seq_length, hidden_size\n",
    "        #x = x.view(-1, int(640*128/(4**self.number_of_block)), self.c_out)\n",
    "        #x, _ = self.LSTM(x)\n",
    "        # print(x.shape) # batch_size, seq_length, hidden_size\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T02:42:49.920295Z",
     "iopub.status.busy": "2021-01-02T02:42:49.919420Z",
     "iopub.status.idle": "2021-01-02T02:42:49.923682Z",
     "shell.execute_reply": "2021-01-02T02:42:49.923073Z"
    },
    "papermill": {
     "duration": 0.026105,
     "end_time": "2021-01-02T02:42:49.923798",
     "exception": false,
     "start_time": "2021-01-02T02:42:49.897693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#             nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "#             nn.BatchNorm2d(192),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#             nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(384),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#         )\n",
    "#         self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "#         self.LSTM = nn.LSTM(36, 20, 2, batch_first = True)\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(5120, 64),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(64, 8),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "#         x = self.features(x)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = x.reshape(-1, 256, 6*6)\n",
    "#         x = self.LSTM(x)[0]\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "\n",
    "# model = Net()\n",
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T02:42:49.961809Z",
     "iopub.status.busy": "2021-01-02T02:42:49.960920Z",
     "iopub.status.idle": "2021-01-02T02:42:49.965696Z",
     "shell.execute_reply": "2021-01-02T02:42:49.965048Z"
    },
    "papermill": {
     "duration": 0.025931,
     "end_time": "2021-01-02T02:42:49.965822",
     "exception": false,
     "start_time": "2021-01-02T02:42:49.939891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T02:42:50.012558Z",
     "iopub.status.busy": "2021-01-02T02:42:50.011451Z",
     "iopub.status.idle": "2021-01-02T02:42:50.014786Z",
     "shell.execute_reply": "2021-01-02T02:42:50.014189Z"
    },
    "papermill": {
     "duration": 0.0329,
     "end_time": "2021-01-02T02:42:50.014924",
     "exception": false,
     "start_time": "2021-01-02T02:42:49.982024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(input_data, model, criterion, optimizer, output_disable = False):\n",
    "\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    total_count = 0\n",
    "    acc_count = 0\n",
    "    pbar = tqdm(input_data, disable = output_disable)\n",
    "    for data in pbar:\n",
    "        pbar.set_description(\"Training\")\n",
    "        music, genre = data[0].cuda(), data[1].cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(music)\n",
    "        loss = criterion(outputs, genre) ##data type\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_count += genre.size(0) \n",
    "        acc_count += (predicted == genre).sum()  \n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "\n",
    "    acc = acc_count.to(\"cpu\").detach().numpy() / total_count\n",
    "    loss = sum(loss_list) / len(loss_list)\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T02:42:50.060369Z",
     "iopub.status.busy": "2021-01-02T02:42:50.059456Z",
     "iopub.status.idle": "2021-01-02T02:42:50.063590Z",
     "shell.execute_reply": "2021-01-02T02:42:50.062850Z"
    },
    "papermill": {
     "duration": 0.032568,
     "end_time": "2021-01-02T02:42:50.063709",
     "exception": false,
     "start_time": "2021-01-02T02:42:50.031141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val(input_data, model, criterion, output_disable = False):\n",
    "    model.eval()\n",
    "    \n",
    "    loss_list = []\n",
    "    total_count = 0\n",
    "    acc_count = 0\n",
    "    pbar = tqdm(input_data, disable = output_disable)\n",
    "    with torch.no_grad():\n",
    "        for data in pbar:\n",
    "            pbar.set_description(\"Validation\")\n",
    "            music, genre = data[0].cuda(), data[1].cuda()\n",
    "            outputs = model(music)\n",
    "            loss = criterion(outputs, genre) ##data type\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total_count += genre.size(0)\n",
    "            acc_count += (predicted == genre).sum()\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "\n",
    "    acc = acc_count.to(\"cpu\").detach().numpy() / total_count\n",
    "    loss = sum(loss_list) / len(loss_list)\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T02:42:50.112732Z",
     "iopub.status.busy": "2021-01-02T02:42:50.109610Z",
     "iopub.status.idle": "2021-01-02T02:42:50.115875Z",
     "shell.execute_reply": "2021-01-02T02:42:50.115273Z"
    },
    "papermill": {
     "duration": 0.036288,
     "end_time": "2021-01-02T02:42:50.115989",
     "exception": false,
     "start_time": "2021-01-02T02:42:50.079701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RNN(parameters ,max_epochs = 3):    \n",
    "    learning_rate = parameters[0]\n",
    "    initial_size, th_1, th_2, number_of_block = tuple(int(param) for param in parameters[1:])\n",
    "    print(\"Learning rate =\", learning_rate, \"Number of block =\",number_of_block)\n",
    "    train_acc_list = []\n",
    "    train_loss_list = []\n",
    "    val_acc_list = []\n",
    "    val_loss_list = []\n",
    "    \n",
    "    design, c_out = configuration(number_of_block, initial_size, th_1, th_2)\n",
    "    convolution = make_layers(design, batch_norm=True)\n",
    "    model = VGG(convolution, number_of_block, c_out)\n",
    "    print(design)\n",
    "    model = model.cuda()\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        print('=' * 20, 'Epoch', epoch, '=' * 20)\n",
    "        train_acc, train_loss = train(train_loader, model, criterion, optimizer, True)\n",
    "        val_acc, val_loss = val(val_loader, model, criterion, True)\n",
    "\n",
    "        train_acc_list.append(train_acc)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "        print('Train Acc: {:.6f} Train Loss: {:.6f}'.format(train_acc, train_loss))\n",
    "        print('  Val Acc: {:.6f}   Val Loss: {:.6f}'.format(val_acc, val_loss))\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T02:42:50.159520Z",
     "iopub.status.busy": "2021-01-02T02:42:50.158408Z",
     "iopub.status.idle": "2021-01-02T02:42:50.161276Z",
     "shell.execute_reply": "2021-01-02T02:42:50.161822Z"
    },
    "papermill": {
     "duration": 0.030081,
     "end_time": "2021-01-02T02:42:50.161972",
     "exception": false,
     "start_time": "2021-01-02T02:42:50.131891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def comparison(parameter, lower_bound, upper_bound, integer = False, mutation_rate = 0.02):\n",
    "    new_parameter = parameter\n",
    "    if parameter > upper_bound:\n",
    "        new_parameter =  np.random.uniform(low = (lower_bound+upper_bound)/2, high = upper_bound)\n",
    "    elif parameter < lower_bound:\n",
    "        new_parameter =  np.random.uniform(low = lower_bound, high = (lower_bound+upper_bound)/2)\n",
    "    else:\n",
    "        if random.uniform(0,1) < mutation_rate:\n",
    "            new_parameter = np.random.uniform(low = lower_bound, high = upper_bound)\n",
    "            print(\"Mutation occur:\", parameter, \"-->\", new_parameter)\n",
    "    if integer:\n",
    "        new_parameter = int(new_parameter)\n",
    "    return new_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T02:42:50.208817Z",
     "iopub.status.busy": "2021-01-02T02:42:50.206659Z",
     "iopub.status.idle": "2021-01-02T02:42:50.209599Z",
     "shell.execute_reply": "2021-01-02T02:42:50.210160Z"
    },
    "papermill": {
     "duration": 0.032346,
     "end_time": "2021-01-02T02:42:50.210330",
     "exception": false,
     "start_time": "2021-01-02T02:42:50.177984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_num = 4  ##粒子個數  initial_size, th_1, th_2, number_of_block\n",
    "max_iteration = 10 ##迭代次數\n",
    "record = np.zeros((1, max_iteration), dtype='float')\n",
    "boundary = [[1e-5, 5e-3], [1, 64], [1,5], [3,7], [1, 7]]\n",
    "x = np.array([[0.001, 32, 3, 5, 7, 0.436250], \n",
    "              [0.0003112003852983763, 44, 2, 5, 4, 0.523750],\n",
    "              [0.0007612228704013985, 26, 2, 6, 4,  0.513750],\n",
    "              [0.0006310624186537511, 33, 2, 6, 3, 0.475000]])\n",
    "x = x.transpose()\n",
    "w = 0.5\n",
    "c1 = 2\n",
    "c2 = 2\n",
    "V = np.zeros((5, p_num))\n",
    "Pb = x\n",
    "Gb = Pb[:, np.argmax(Pb[5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-02T02:42:50.369500Z",
     "iopub.status.busy": "2021-01-02T02:42:50.368718Z",
     "iopub.status.idle": "2021-01-02T10:53:30.497521Z",
     "shell.execute_reply": "2021-01-02T10:53:30.498426Z"
    },
    "papermill": {
     "duration": 29440.272246,
     "end_time": "2021-01-02T10:53:30.498611",
     "exception": false,
     "start_time": "2021-01-02T02:42:50.226365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Iteration 1 --------------------\n",
      ".................... Particle 1 ....................\n",
      "Learning rate = 0.00074155116568344 Number of block = 6\n",
      "[54, 'M', 108, 'M', 216, 216, 'M', 432, 432, 'M', 864, 864, 'M', 432, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.253832 Train Loss: 1.940217\n",
      "  Val Acc: 0.207500   Val Loss: 2.375772\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.352205 Train Loss: 1.718199\n",
      "  Val Acc: 0.263750   Val Loss: 1.896855\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.396935 Train Loss: 1.642892\n",
      "  Val Acc: 0.298750   Val Loss: 2.144374\n",
      ".................... Particle 2 ....................\n",
      "Learning rate = 0.0003112003852983763 Number of block = 4\n",
      "[44, 'M', 88, 'M', 176, 176, 'M', 352, 352, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.213951 Train Loss: 2.490623\n",
      "  Val Acc: 0.325000   Val Loss: 1.750831\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.315608 Train Loss: 1.807083\n",
      "  Val Acc: 0.386250   Val Loss: 1.684115\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.337348 Train Loss: 1.742408\n",
      "  Val Acc: 0.402500   Val Loss: 1.620841\n",
      ".................... Particle 3 ....................\n",
      "Learning rate = 0.0006764838275202769 Number of block = 4\n",
      "[44, 'M', 88, 'M', 176, 176, 'M', 352, 352, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.217704 Train Loss: 2.905385\n",
      "  Val Acc: 0.225000   Val Loss: 1.982444\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.263997 Train Loss: 1.907267\n",
      "  Val Acc: 0.215000   Val Loss: 1.871020\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.274632 Train Loss: 1.869598\n",
      "  Val Acc: 0.248750   Val Loss: 1.887454\n",
      ".................... Particle 4 ....................\n",
      "Learning rate = 0.0004551431539952612 Number of block = 4\n",
      "[34, 'M', 68, 'M', 136, 136, 'M', 272, 272, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.230685 Train Loss: 2.444676\n",
      "  Val Acc: 0.283750   Val Loss: 1.882717\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.290429 Train Loss: 1.846236\n",
      "  Val Acc: 0.336250   Val Loss: 1.703958\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.331874 Train Loss: 1.779071\n",
      "  Val Acc: 0.443750   Val Loss: 1.601618\n",
      "[4.55143154e-04 3.40000000e+01 2.00000000e+00 5.00000000e+00\n",
      " 4.00000000e+00 4.43750000e-01]\n",
      "-------------------- Iteration 2 --------------------\n",
      ".................... Particle 1 ....................\n",
      "Learning rate = 0.0004932836193020586 Number of block = 4\n",
      "[31, 'M', 62, 62, 'M', 124, 124, 'M', 248, 248, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.217548 Train Loss: 2.434295\n",
      "  Val Acc: 0.258750   Val Loss: 1.832553\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.287144 Train Loss: 1.852965\n",
      "  Val Acc: 0.317500   Val Loss: 1.813607\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.300125 Train Loss: 1.812605\n",
      "  Val Acc: 0.345000   Val Loss: 1.734505\n",
      ".................... Particle 2 ....................\n",
      "Learning rate = 0.0005206738298195369 Number of block = 4\n",
      "[38, 'M', 76, 'M', 152, 152, 'M', 304, 304, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.218955 Train Loss: 2.657365\n",
      "  Val Acc: 0.288750   Val Loss: 1.878058\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.304817 Train Loss: 1.829047\n",
      "  Val Acc: 0.362500   Val Loss: 1.663943\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.335158 Train Loss: 1.753102\n",
      "  Val Acc: 0.426250   Val Loss: 1.597153\n",
      ".................... Particle 3 ....................\n",
      "Learning rate = 0.0003938604637398067 Number of block = 4\n",
      "[39, 'M', 78, 'M', 156, 156, 'M', 312, 312, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.225680 Train Loss: 2.517242\n",
      "  Val Acc: 0.337500   Val Loss: 1.785126\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.321708 Train Loss: 1.811350\n",
      "  Val Acc: 0.346250   Val Loss: 1.716969\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.351892 Train Loss: 1.754814\n",
      "  Val Acc: 0.357500   Val Loss: 1.713479\n",
      ".................... Particle 4 ....................\n",
      "Learning rate = 0.0003671835216660162 Number of block = 4\n",
      "[34, 'M', 68, 'M', 136, 136, 'M', 272, 272, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.251173 Train Loss: 2.265940\n",
      "  Val Acc: 0.337500   Val Loss: 1.795050\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.330310 Train Loss: 1.783638\n",
      "  Val Acc: 0.330000   Val Loss: 1.776461\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.380357 Train Loss: 1.679882\n",
      "  Val Acc: 0.426250   Val Loss: 1.551159\n",
      "[3.67183522e-04 3.40000000e+01 2.00000000e+00 4.00000000e+00\n",
      " 4.00000000e+00 4.26250000e-01]\n",
      "-------------------- Iteration 3 --------------------\n",
      ".................... Particle 1 ....................\n",
      "Learning rate = 0.00026378013178530107 Number of block = 3\n",
      "[22, 'M', 44, 'M', 88, 88, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.248201 Train Loss: 2.341499\n",
      "  Val Acc: 0.387500   Val Loss: 1.699884\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.345167 Train Loss: 1.738435\n",
      "  Val Acc: 0.436250   Val Loss: 1.595057\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.389897 Train Loss: 1.639128\n",
      "  Val Acc: 0.468750   Val Loss: 1.497547\n",
      ".................... Particle 2 ....................\n",
      "Learning rate = 0.0005842415500888034 Number of block = 4\n",
      "[31, 'M', 62, 'M', 124, 124, 'M', 62, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.295746 Train Loss: 1.910017\n",
      "  Val Acc: 0.367500   Val Loss: 1.668727\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.386769 Train Loss: 1.649384\n",
      "  Val Acc: 0.440000   Val Loss: 1.595225\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.454958 Train Loss: 1.533394\n",
      "  Val Acc: 0.466250   Val Loss: 1.521829\n",
      ".................... Particle 3 ....................\n",
      "Learning rate = 0.00023411823667011055 Number of block = 4\n",
      "[29, 'M', 58, 'M', 116, 116, 'M', 58, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.336096 Train Loss: 1.781802\n",
      "  Val Acc: 0.440000   Val Loss: 1.557681\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.451361 Train Loss: 1.517581\n",
      "  Val Acc: 0.513750   Val Loss: 1.399990\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.510166 Train Loss: 1.407526\n",
      "  Val Acc: 0.531250   Val Loss: 1.439475\n",
      ".................... Particle 4 ....................\n",
      "Learning rate = 0.0003232037055013937 Number of block = 4\n",
      "[34, 'M', 68, 'M', 136, 136, 'M', 68, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.337817 Train Loss: 1.787636\n",
      "  Val Acc: 0.466250   Val Loss: 1.497066\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.448233 Train Loss: 1.544545\n",
      "  Val Acc: 0.486250   Val Loss: 1.487346\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.492337 Train Loss: 1.439055\n",
      "  Val Acc: 0.496250   Val Loss: 1.454897\n",
      "[2.34118237e-04 2.90000000e+01 2.00000000e+00 3.00000000e+00\n",
      " 4.00000000e+00 5.31250000e-01]\n",
      "-------------------- Iteration 4 --------------------\n",
      ".................... Particle 1 ....................\n",
      "Learning rate = 0.00011062259152612729 Number of block = 3\n",
      "[21, 'M', 42, 42, 'M', 84, 84, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.295590 Train Loss: 1.915603\n",
      "  Val Acc: 0.396250   Val Loss: 1.594807\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.398968 Train Loss: 1.626236\n",
      "  Val Acc: 0.468750   Val Loss: 1.485684\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.438693 Train Loss: 1.552361\n",
      "  Val Acc: 0.468750   Val Loss: 1.457996\n",
      ".................... Particle 2 ....................\n",
      "Learning rate = 3.686397057036045e-05 Number of block = 4\n",
      "[25, 'M', 50, 'M', 100, 100, 'M', 50, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.284642 Train Loss: 1.863898\n",
      "  Val Acc: 0.377500   Val Loss: 1.653631\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.394276 Train Loss: 1.648286\n",
      "  Val Acc: 0.448750   Val Loss: 1.512210\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.447764 Train Loss: 1.533292\n",
      "  Val Acc: 0.475000   Val Loss: 1.452458\n",
      ".................... Particle 3 ....................\n",
      "Learning rate = 0.00015424712313526247 Number of block = 4\n",
      "[24, 'M', 48, 'M', 96, 96, 'M', 48, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.316547 Train Loss: 1.791626\n",
      "  Val Acc: 0.397500   Val Loss: 1.565779\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.440569 Train Loss: 1.535593\n",
      "  Val Acc: 0.477500   Val Loss: 1.453116\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.508602 Train Loss: 1.394255\n",
      "  Val Acc: 0.513750   Val Loss: 1.428314\n",
      ".................... Particle 4 ....................\n",
      "Learning rate = 0.0012618863816721878 Number of block = 4\n",
      "[17, 'M', 34, 'M', 68, 68, 'M', 34, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.262434 Train Loss: 2.031597\n",
      "  Val Acc: 0.331250   Val Loss: 1.797816\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.352987 Train Loss: 1.722628\n",
      "  Val Acc: 0.410000   Val Loss: 1.651477\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.400219 Train Loss: 1.635469\n",
      "  Val Acc: 0.413750   Val Loss: 1.670802\n",
      "[1.54247123e-04 2.40000000e+01 2.00000000e+00 3.00000000e+00\n",
      " 4.00000000e+00 5.13750000e-01]\n",
      "-------------------- Iteration 5 --------------------\n",
      ".................... Particle 1 ....................\n",
      "Learning rate = 7.986197598595574e-05 Number of block = 4\n",
      "[22, 'M', 44, 44, 'M', 88, 88, 'M', 44, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.303722 Train Loss: 1.812878\n",
      "  Val Acc: 0.387500   Val Loss: 1.607770\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.438380 Train Loss: 1.567235\n",
      "  Val Acc: 0.472500   Val Loss: 1.454755\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.488739 Train Loss: 1.434152\n",
      "  Val Acc: 0.530000   Val Loss: 1.402205\n",
      ".................... Particle 2 ....................\n",
      "Learning rate = 0.0005416807005567284 Number of block = 4\n",
      "[20, 'M', 40, 'M', 80, 80, 'M', 160, 160, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.241789 Train Loss: 2.223033\n",
      "  Val Acc: 0.327500   Val Loss: 1.794823\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.331248 Train Loss: 1.779101\n",
      "  Val Acc: 0.345000   Val Loss: 1.690517\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.363622 Train Loss: 1.690266\n",
      "  Val Acc: 0.423750   Val Loss: 1.544893\n",
      ".................... Particle 3 ....................\n",
      "Learning rate = 0.00011431156636783844 Number of block = 4\n",
      "[21, 'M', 42, 'M', 84, 84, 'M', 42, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.316547 Train Loss: 1.804084\n",
      "  Val Acc: 0.387500   Val Loss: 1.602866\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.441508 Train Loss: 1.547976\n",
      "  Val Acc: 0.456250   Val Loss: 1.493050\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.495777 Train Loss: 1.410919\n",
      "  Val Acc: 0.476250   Val Loss: 1.458993\n",
      ".................... Particle 4 ....................\n",
      "Learning rate = 0.0013013364851438957 Number of block = 4\n",
      "[9, 'M', 18, 'M', 36, 36, 'M', 72, 72, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.223334 Train Loss: 2.340578\n",
      "  Val Acc: 0.290000   Val Loss: 1.898709\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.269002 Train Loss: 1.857595\n",
      "  Val Acc: 0.287500   Val Loss: 1.855963\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.303879 Train Loss: 1.811901\n",
      "  Val Acc: 0.350000   Val Loss: 1.732661\n",
      "[7.9861976e-05 2.2000000e+01 1.0000000e+00 3.0000000e+00 4.0000000e+00\n",
      " 5.3000000e-01]\n",
      "-------------------- Iteration 6 --------------------\n",
      ".................... Particle 1 ....................\n",
      "Learning rate = 6.448166821586996e-05 Number of block = 4\n",
      "[22, 'M', 44, 44, 'M', 88, 88, 'M', 44, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.308414 Train Loss: 1.822491\n",
      "  Val Acc: 0.406250   Val Loss: 1.573934\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.425242 Train Loss: 1.579127\n",
      "  Val Acc: 0.455000   Val Loss: 1.445331\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.483578 Train Loss: 1.443968\n",
      "  Val Acc: 0.511250   Val Loss: 1.397330\n",
      ".................... Particle 2 ....................\n",
      "Learning rate = 0.00019663975910533753 Number of block = 4\n",
      "[18, 'M', 36, 36, 'M', 72, 72, 'M', 144, 144, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.295433 Train Loss: 1.877045\n",
      "  Val Acc: 0.406250   Val Loss: 1.606001\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.410541 Train Loss: 1.599200\n",
      "  Val Acc: 0.473750   Val Loss: 1.520017\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.473256 Train Loss: 1.480126\n",
      "  Val Acc: 0.490000   Val Loss: 1.513712\n",
      ".................... Particle 3 ....................\n",
      "Learning rate = 0.00045136882395478055 Number of block = 4\n",
      "[21, 'M', 42, 42, 'M', 84, 84, 'M', 42, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.322021 Train Loss: 1.795049\n",
      "  Val Acc: 0.385000   Val Loss: 1.618959\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.435095 Train Loss: 1.552424\n",
      "  Val Acc: 0.433750   Val Loss: 1.573437\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.502502 Train Loss: 1.437007\n",
      "  Val Acc: 0.475000   Val Loss: 1.598972\n",
      ".................... Particle 4 ....................\n",
      "Learning rate = 0.00012973308293607724 Number of block = 4\n",
      "[9, 'M', 18, 18, 'M', 36, 36, 'M', 18, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.282452 Train Loss: 1.867509\n",
      "  Val Acc: 0.351250   Val Loss: 1.685849\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.403190 Train Loss: 1.646046\n",
      "  Val Acc: 0.402500   Val Loss: 1.570413\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.465280 Train Loss: 1.498630\n",
      "  Val Acc: 0.435000   Val Loss: 1.488381\n",
      "[6.44816682e-05 2.20000000e+01 1.00000000e+00 3.00000000e+00\n",
      " 4.00000000e+00 5.11250000e-01]\n",
      "-------------------- Iteration 7 --------------------\n",
      ".................... Particle 1 ....................\n",
      "Learning rate = 5.679151433082707e-05 Number of block = 4\n",
      "[22, 'M', 44, 44, 'M', 88, 88, 'M', 44, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.298874 Train Loss: 1.832661\n",
      "  Val Acc: 0.345000   Val Loss: 1.660519\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.418830 Train Loss: 1.610490\n",
      "  Val Acc: 0.430000   Val Loss: 1.497450\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.468721 Train Loss: 1.494605\n",
      "  Val Acc: 0.476250   Val Loss: 1.435561\n",
      ".................... Particle 2 ....................\n",
      "Learning rate = 0.0003605263931322442 Number of block = 4\n",
      "[25, 'M', 50, 50, 'M', 100, 100, 'M', 50, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.327495 Train Loss: 1.802255\n",
      "  Val Acc: 0.431250   Val Loss: 1.558998\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.437285 Train Loss: 1.539905\n",
      "  Val Acc: 0.490000   Val Loss: 1.427225\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.490773 Train Loss: 1.436946\n",
      "  Val Acc: 0.497500   Val Loss: 1.432106\n",
      ".................... Particle 3 ....................\n",
      "Learning rate = 0.00023980511092189076 Number of block = 4\n",
      "[22, 'M', 44, 'M', 88, 88, 'M', 44, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.331248 Train Loss: 1.781534\n",
      "  Val Acc: 0.431250   Val Loss: 1.540234\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.452143 Train Loss: 1.525581\n",
      "  Val Acc: 0.511250   Val Loss: 1.419969\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.505630 Train Loss: 1.408875\n",
      "  Val Acc: 0.515000   Val Loss: 1.427663\n",
      ".................... Particle 4 ....................\n",
      "Learning rate = 0.0009455834536587185 Number of block = 4\n",
      "[10, 'M', 20, 'M', 40, 40, 'M', 80, 80, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.246481 Train Loss: 2.251277\n",
      "  Val Acc: 0.313750   Val Loss: 1.832974\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.329528 Train Loss: 1.770190\n",
      "  Val Acc: 0.352500   Val Loss: 1.717022\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.374883 Train Loss: 1.695245\n",
      "  Val Acc: 0.328750   Val Loss: 1.680511\n",
      "[2.39805111e-04 2.20000000e+01 2.00000000e+00 3.00000000e+00\n",
      " 4.00000000e+00 5.15000000e-01]\n",
      "-------------------- Iteration 8 --------------------\n",
      ".................... Particle 1 ....................\n",
      "Learning rate = 0.00013284172297755716 Number of block = 4\n",
      "[22, 'M', 44, 'M', 88, 88, 'M', 176, 176, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.302158 Train Loss: 1.870461\n",
      "  Val Acc: 0.406250   Val Loss: 1.605343\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.415233 Train Loss: 1.594874\n",
      "  Val Acc: 0.475000   Val Loss: 1.469009\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.482327 Train Loss: 1.479562\n",
      "  Val Acc: 0.495000   Val Loss: 1.463775\n",
      ".................... Particle 2 ....................\n",
      "Learning rate = 0.0001872332796605464 Number of block = 4\n",
      "[28, 'M', 56, 'M', 112, 112, 'M', 224, 224, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.285737 Train Loss: 1.938900\n",
      "  Val Acc: 0.397500   Val Loss: 1.614591\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.417266 Train Loss: 1.607415\n",
      "  Val Acc: 0.441250   Val Loss: 1.544263\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.459806 Train Loss: 1.512283\n",
      "  Val Acc: 0.490000   Val Loss: 1.531929\n",
      ".................... Particle 3 ....................\n",
      "Learning rate = 0.00013402325440544586 Number of block = 4\n",
      "[22, 'M', 44, 44, 'M', 88, 88, 'M', 44, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.333594 Train Loss: 1.760486\n",
      "  Val Acc: 0.416250   Val Loss: 1.548371\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.463403 Train Loss: 1.491139\n",
      "  Val Acc: 0.482500   Val Loss: 1.452685\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.519862 Train Loss: 1.372212\n",
      "  Val Acc: 0.525000   Val Loss: 1.400407\n",
      ".................... Particle 4 ....................\n",
      "Learning rate = 0.0010015887220462944 Number of block = 4\n",
      "[27, 'M', 54, 54, 'M', 108, 108, 'M', 216, 216, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.192681 Train Loss: 2.928751\n",
      "  Val Acc: 0.280000   Val Loss: 1.859269\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.256647 Train Loss: 1.903935\n",
      "  Val Acc: 0.260000   Val Loss: 1.876684\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.270097 Train Loss: 1.869936\n",
      "  Val Acc: 0.296250   Val Loss: 1.811994\n",
      "[1.34023254e-04 2.20000000e+01 1.00000000e+00 3.00000000e+00\n",
      " 4.00000000e+00 5.25000000e-01]\n",
      "-------------------- Iteration 9 --------------------\n",
      ".................... Particle 1 ....................\n",
      "Learning rate = 0.00017282401817570811 Number of block = 4\n",
      "[22, 'M', 44, 44, 'M', 88, 88, 'M', 176, 176, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.297936 Train Loss: 1.890838\n",
      "  Val Acc: 0.412500   Val Loss: 1.613900\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.423209 Train Loss: 1.585539\n",
      "  Val Acc: 0.445000   Val Loss: 1.555382\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.482953 Train Loss: 1.464391\n",
      "  Val Acc: 0.458750   Val Loss: 1.494266\n",
      ".................... Particle 2 ....................\n",
      "Learning rate = 6.043512276482729e-05 Number of block = 4\n",
      "[22, 'M', 44, 'M', 88, 88, 'M', 176, 176, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.308414 Train Loss: 1.829152\n",
      "  Val Acc: 0.385000   Val Loss: 1.611612\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.430404 Train Loss: 1.576331\n",
      "  Val Acc: 0.451250   Val Loss: 1.498872\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.492649 Train Loss: 1.442802\n",
      "  Val Acc: 0.493750   Val Loss: 1.407935\n",
      ".................... Particle 3 ....................\n",
      "Learning rate = 8.113232614722341e-05 Number of block = 4\n",
      "[22, 'M', 44, 44, 'M', 88, 88, 'M', 44, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.291836 Train Loss: 1.841420\n",
      "  Val Acc: 0.380000   Val Loss: 1.642850\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.420238 Train Loss: 1.594567\n",
      "  Val Acc: 0.448750   Val Loss: 1.498319\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.486863 Train Loss: 1.447694\n",
      "  Val Acc: 0.482500   Val Loss: 1.462101\n",
      ".................... Particle 4 ....................\n",
      "Learning rate = 0.002272548461991036 Number of block = 4\n",
      "[33, 'M', 66, 66, 'M', 132, 132, 'M', 66, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.197998 Train Loss: 2.625398\n",
      "  Val Acc: 0.238750   Val Loss: 2.104193\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.248514 Train Loss: 1.912810\n",
      "  Val Acc: 0.225000   Val Loss: 1.953684\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.265874 Train Loss: 1.887695\n",
      "  Val Acc: 0.236250   Val Loss: 2.086138\n",
      "[6.04351228e-05 2.20000000e+01 2.00000000e+00 4.00000000e+00\n",
      " 4.00000000e+00 4.93750000e-01]\n",
      "-------------------- Iteration 10 --------------------\n",
      ".................... Particle 1 ....................\n",
      "Learning rate = 7.630639103712198e-05 Number of block = 4\n",
      "[22, 'M', 44, 44, 'M', 88, 88, 'M', 44, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.319049 Train Loss: 1.805321\n",
      "  Val Acc: 0.396250   Val Loss: 1.573919\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.451673 Train Loss: 1.543543\n",
      "  Val Acc: 0.476250   Val Loss: 1.449698\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.497498 Train Loss: 1.430466\n",
      "  Val Acc: 0.516250   Val Loss: 1.378318\n",
      ".................... Particle 2 ....................\n",
      "Learning rate = 0.002492120393789772 Number of block = 4\n",
      "[19, 'M', 38, 38, 'M', 76, 76, 'M', 38, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.195496 Train Loss: 2.361824\n",
      "  Val Acc: 0.221250   Val Loss: 1.977877\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.234751 Train Loss: 1.939457\n",
      "  Val Acc: 0.180000   Val Loss: 2.208384\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.236472 Train Loss: 1.916098\n",
      "  Val Acc: 0.248750   Val Loss: 1.859888\n",
      ".................... Particle 3 ....................\n",
      "Learning rate = 0.004639997480546889 Number of block = 4\n",
      "[16, 'M', 32, 'M', 64, 64, 'M', 128, 128, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.161401 Train Loss: 6.372062\n",
      "  Val Acc: 0.233750   Val Loss: 2.015971\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.207695 Train Loss: 1.988093\n",
      "  Val Acc: 0.181250   Val Loss: 1.960019\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.225524 Train Loss: 1.954315\n",
      "  Val Acc: 0.255000   Val Loss: 1.974463\n",
      ".................... Particle 4 ....................\n",
      "Learning rate = 0.0018968505280903105 Number of block = 4\n",
      "[28, 'M', 56, 'M', 112, 112, 'M', 56, 'M']\n",
      "==================== Epoch 1 ====================\n",
      "Train Acc: 0.217860 Train Loss: 2.378081\n",
      "  Val Acc: 0.181250   Val Loss: 2.062239\n",
      "==================== Epoch 2 ====================\n",
      "Train Acc: 0.290585 Train Loss: 1.842398\n",
      "  Val Acc: 0.325000   Val Loss: 1.822694\n",
      "==================== Epoch 3 ====================\n",
      "Train Acc: 0.296997 Train Loss: 1.817663\n",
      "  Val Acc: 0.303750   Val Loss: 1.831611\n",
      "[7.6306391e-05 2.2000000e+01 1.0000000e+00 3.0000000e+00 4.0000000e+00\n",
      " 5.1625000e-01]\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_iteration):\n",
    "    print('-' * 20, 'Iteration', i+1, '-' * 20)\n",
    "    for j in range(p_num):\n",
    "        print('.' * 20, 'Particle', j+1, '.' * 20)\n",
    "        for k in range(5):\n",
    "            V[k,j] = w * V[k,j] + c1 * random.uniform(0,1) * (Pb[k,j] - x[k,j]) + c2 * random.uniform(0,1) * (Gb[k] - x[k,j])  ##計算速度\n",
    "            x[k,j] += V[k,j]  ##更新位置\n",
    "            x[k,j] = comparison(x[k,j], boundary[k][0], boundary[k][1], (k != 0))\n",
    "        gc.collect()\n",
    "        with torch.no_grad():\n",
    "            torch.cuda.empty_cache()\n",
    "        time.sleep(10)\n",
    "        x[5,j] = RNN(x[:5,j].tolist())\n",
    "    for j in range(p_num): ##每個粒子的最好位置更新\n",
    "        if Pb[5,j] < x[5,j]:\n",
    "            Pb[:,j] = x[:,j]\n",
    "    if Gb[5] < max(Pb[5]): \n",
    "        Gb = Pb[:, np.argmax(Pb[5])]\n",
    "    print(Gb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 29507.109704,
   "end_time": "2021-01-02T10:53:31.699660",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-02T02:41:44.589956",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
